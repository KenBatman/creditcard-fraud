import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
import joblib
import os
import streamlit as st  # Th√™m import st ƒë·ªÉ d√πng session_state n·∫øu c·∫ßn (t√πy ch·ªçn)

def load_and_preprocess_data(df=None, csv_path="Data/creditcard.csv"):
    """
    Load v√† preprocess data. ∆Øu ti√™n d√πng df n·∫øu cung c·∫•p (t·ª´ upload), fallback load CSV.
    """
    try:
        if df is not None:
            # D√πng df t·ª´ upload (kh√¥ng c·∫ßn read CSV)
            print("üìÇ S·ª≠ d·ª•ng df t·ª´ upload...")
            df_local = df.copy()
        else:
            # Fallback load CSV
            if not os.path.exists(csv_path):
                raise FileNotFoundError(f"‚ùå File CSV kh√¥ng t·ªìn t·∫°i: {csv_path}. Vui l√≤ng upload dataset ho·∫∑c ƒë·∫∑t file ·ªü Data/creditcard.csv.")
            print(f"üìÇ ƒêang load t·ª´ {csv_path}...")
            df_local = pd.read_csv(csv_path)
        
        df_local = df_local.drop_duplicates()
        print(f"üìä D·ªØ li·ªáu sau drop duplicates: {df_local.shape}")
        
        # Fit v√† transform Amount/Time v·ªõi scaler ri√™ng, r·ªìi dump ch√∫ng
        amount_scaler = StandardScaler()
        df_local['normAmount'] = amount_scaler.fit_transform(df_local[['Amount']])
        os.makedirs("models", exist_ok=True)
        joblib.dump(amount_scaler, "models/amount_scaler.pkl")
        print("‚úÖ Dumped amount_scaler.pkl")
        
        time_scaler = StandardScaler()
        df_local['normTime'] = time_scaler.fit_transform(df_local[['Time']])
        joblib.dump(time_scaler, "models/time_scaler.pkl")
        print("‚úÖ Dumped time_scaler.pkl")
        
        df_local = df_local.drop(['Amount', 'Time'], axis=1)
        tar_col = "Class"
        X = df_local.drop('Class', axis=1)
        y = df_local['Class']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
        print("‚úÖ Preprocess ho√†n t·∫•t. Train shape:", X_train.shape)
        return X_train, X_test, y_train, y_test, X.columns
        
    except FileNotFoundError as e:
        # Raise ƒë·ªÉ UI catch v√† show error
        raise RuntimeError(f"L·ªói load data: {e}. ƒê·∫£m b·∫£o upload dataset creditcard.csv.")
    except Exception as e:
        raise RuntimeError(f"L·ªói preprocess: {e}")

def train_logistic_regression(X_train, y_train):
    pipe = Pipeline([
        ('scaler', RobustScaler()),
        ('smote', SMOTE(random_state=42, sampling_strategy=0.3)),
        ('model', LogisticRegression(max_iter=1000))
    ])
    pipe.fit(X_train, y_train)
    return pipe

def train_xgboost(X_train, y_train):
    pipe = Pipeline([
        ('scaler', RobustScaler()),
        ('smote', SMOTE(random_state=42, sampling_strategy=0.3)),
        ('model', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))
    ])
    pipe.fit(X_train, y_train)
    return pipe

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    report = classification_report(y_test, y_pred, output_dict=True)
    auc = roc_auc_score(y_test, y_proba)
    cm = confusion_matrix(y_test, y_pred)
    return {"report": report, "auc": auc, "confusion_matrix": cm}

def train_and_save_models(df=None):  # Th√™m param df ƒë·ªÉ pass t·ª´ Interface.py
    os.makedirs("models", exist_ok=True)

    # ‚ö° N·∫øu models ƒë√£ t·ªìn t·∫°i, load l·∫°i thay v√¨ train l·∫°i
    if os.path.exists("models/logistic_regression.pkl") and os.path.exists("models/xgboost.pkl"):
        print("üìÇ Models ƒë√£ t·ªìn t·∫°i ‚Äî ƒëang load l·∫°i t·ª´ th∆∞ m·ª•c /models ...")

        # Load models
        lr_model = joblib.load("models/logistic_regression.pkl")
        xgb_model = joblib.load("models/xgboost.pkl")

        # Load d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° l·∫°i model (pass df n·∫øu c√≥)
        X_train, X_test, y_train, y_test, _ = load_and_preprocess_data(df=df)
        results = {
            "Logistic Regression": evaluate_model(lr_model, X_test, y_test),
            "XGBoost": evaluate_model(xgb_model, X_test, y_test)
        }
        return results

    # ‚öôÔ∏è N·∫øu ch∆∞a c√≥ model ‚Äî ti·∫øn h√†nh train m·ªõi
    print("üöÄ ƒêang hu·∫•n luy·ªán models m·ªõi...")
    X_train, X_test, y_train, y_test, feature_names = load_and_preprocess_data(df=df)
    results = {}

    # Logistic Regression
    lr_model = train_logistic_regression(X_train, y_train)
    joblib.dump(lr_model, "models/logistic_regression.pkl")
    results["Logistic Regression"] = evaluate_model(lr_model, X_test, y_test)

    # XGBoost
    xgb_model = train_xgboost(X_train, y_train)
    joblib.dump(xgb_model, "models/xgboost.pkl")
    results["XGBoost"] = evaluate_model(xgb_model, X_test, y_test)

    print("‚úÖ ƒê√£ hu·∫•n luy·ªán v√† l∆∞u models v√†o th∆∞ m·ª•c /models")
    return results

def user_predict(input_data: dict, model_name="Logistic Regression"):
    """
    D·ª± ƒëo√°n giao d·ªãch m·ªõi d·ª±a tr√™n input user nh·∫≠p v√†o.
    input_data: dict c√≥ c√°c c·ªôt ['V1'...'V28', 'Amount', 'Time']
    model_name: "Logistic Regression" ho·∫∑c "XGBoost"
    """
    try:
        # Load hai scaler ƒë√£ fit
        if not os.path.exists("models/amount_scaler.pkl"):
            raise FileNotFoundError("‚ùå Ch∆∞a train models. Vui l√≤ng ch·∫°y Tab 'Train Models' tr∆∞·ªõc.")
        amount_scaler = joblib.load("models/amount_scaler.pkl")
        time_scaler = joblib.load("models/time_scaler.pkl")

        # Load model
        model_path = (
            "models/logistic_regression.pkl"
            if model_name == "Logistic Regression"
            else "models/xgboost.pkl"
        )
        model = joblib.load(model_path)

        # T·∫°o DataFrame t·ª´ input
        df_input = pd.DataFrame([input_data])
        
        # Transform Amount v√† Time ri√™ng
        df_input['normAmount'] = amount_scaler.transform(df_input[['Amount']])
        df_input['normTime'] = time_scaler.transform(df_input[['Time']])
        
        # Drop c·ªôt g·ªëc
        df_input = df_input.drop(['Amount', 'Time'], axis=1)
        
        # D·ª± ƒëo√°n
        prediction = model.predict(df_input)[0]
        probability = model.predict_proba(df_input)[0][1]
        
        return int(prediction), float(probability)  # Tr·∫£ v·ªÅ tuple ƒë·ªÉ kh·ªõp Interface.py
        
    except Exception as e:
        raise RuntimeError(f"L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {e}")